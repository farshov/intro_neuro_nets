{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "imp\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import random\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEVICE_ID = 3\n",
    "DEVICE = torch.device('cuda:%d' % 0)\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Для запуска без GPU раскомментировать и закоментировать код выше\n",
    "#DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100500)\n",
    "\n",
    "def data2image(data):\n",
    "    res = np.transpose(np.reshape(data ,(3, 32,32)), (1,2,0))\n",
    "    return PIL.Image.fromarray(np.uint8(res))\n",
    "\n",
    "def imshow(img):\n",
    "    if isinstance(img, torch.Tensor): img = img.numpy().astype('uint8')\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    \n",
    "def prediction2classes(output_var):\n",
    "    _, predicted = torch.max(output_var.data, 1)\n",
    "    predicted.squeeze_()\n",
    "    classes = predicted.tolist()\n",
    "    return classes\n",
    "\n",
    "def make_solution_pytorch(net, input_tensor, a_batch_size):\n",
    "    res = []\n",
    "    net = net.eval()\n",
    "    cur_pos = 0\n",
    "    while cur_pos <= len(input_tensor):\n",
    "        outputs = net(input_tensor[cur_pos:cur_pos+a_batch_size])\n",
    "        res += prediction2classes(outputs)\n",
    "        cur_pos += a_batch_size\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "class CifarDataset(Dataset):\n",
    "    def __init__(self, input_path, is_train=True, transform=None):\n",
    "                        \n",
    "        data = np.load(input_path)\n",
    "        if is_train: \n",
    "            self.Y, self.X = np.hsplit(data, [1]) \n",
    "            self.Y = [item[0] for item in self.Y]\n",
    "        else: \n",
    "            self.X = data\n",
    "            self.Y = None\n",
    "            \n",
    "        self.X = self.X.reshape((self.X.shape[0], 3, 32, 32))\n",
    "        self.X = self.X.transpose((0, 2, 3, 1)) #приводим к виду (N, H, W, C)\n",
    "        self.X = [Image.fromarray(img) for img in self.X]\n",
    "                \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.X[idx]\n",
    "\n",
    "        if self.transform: sample = self.transform(sample)\n",
    "\n",
    "        if self.Y is None: return sample\n",
    "        else: return (sample, self.Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Надо поменять пути на свои до файлов с kaggle\n",
    "#DATA_PATH  = '/Users/ilyabasharov/Programs/Projects of mail.ru/Neural networks/4 homework/'\n",
    "train_path = 'kaggle_1/homework_4.train.npy'\n",
    "test_path  = 'kaggle_1/homework_4_no_classes.test.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mean = np.mean([item[0].numpy() for item in CifarDataset(train_path, transform=transforms.ToTensor())], axis=(0,2,3))\n",
    "np_std = np.std([item[0].numpy() for item in CifarDataset(train_path, transform=transforms.ToTensor())], axis=(0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_transform_norm = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")\n",
    "\n",
    "cifar_test_transform_norm = transforms.Compose([    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.FloatTensor(np_mean), torch.FloatTensor(np_std))\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_norm = CifarDataset(train_path, transform=cifar_transform_norm)\n",
    "dataloader_train_norm = DataLoader(dataset_train_norm, batch_size=128,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "dataset_test_norm = CifarDataset(test_path, is_train=False, transform=cifar_test_transform_norm)\n",
    "dataloader_test_norm = DataLoader(dataset_test_norm, batch_size=128,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "def train_network(a_net, \n",
    "                  a_device,\n",
    "                  dataloader_train_norm=dataloader_train_norm,\n",
    "                  a_epochs=110,\n",
    "                  a_batch_size=128,\n",
    "                  a_lr=0.1):\n",
    "    \n",
    "    train_acc = []\n",
    "    net = a_net.to(a_device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr, weight_decay=0.001, momentum=0.9)\n",
    "\n",
    "    \n",
    "    for epoch in tqdrange(a_epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        if (epoch == 80 ): \n",
    "            a_lr = a_lr/10\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr, weight_decay=0.005, momentum=0.9) \n",
    "        if (epoch == 95 ): \n",
    "            a_lr = a_lr/10\n",
    "            optimizer = torch.optim.SGD(a_net.parameters(), lr=a_lr, weight_decay=0.005, momentum=0.9) \n",
    "        \n",
    "        net = net.train()        \n",
    "        epoch_accuracy = 0.0\n",
    "        epoch_iters = 0\n",
    "        for item in dataloader_train_norm:\n",
    "            \n",
    "            epoch_iters += 1\n",
    "\n",
    "            inputs = item[0].to(a_device)\n",
    "            labels = item[1].long().to(a_device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            new_labels = labels.to('cpu')\n",
    "            epoch_accuracy += accuracy_score(new_labels, prediction2classes(outputs))\n",
    "\n",
    "        epoch_accuracy /= epoch_iters\n",
    "        train_acc.append(epoch_accuracy)\n",
    "        \n",
    "        print(\"Epoch \", epoch, round(train_acc[-1], 4))\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "    plt.plot(train_acc, label='Train')\n",
    "    plt.legend()\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StupidDenseNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(StupidDenseNet, self).__init__()\n",
    "        \n",
    "        #Один из способов задать сеть - это задать последовательность слоев через Sequential\n",
    "        self.classifier = nn.Sequential()\n",
    "        self.classifier.add_module('lin1', nn.Linear(3*32*32, 500))\n",
    "        self.classifier.add_module('sig1', torch.nn.Sigmoid())\n",
    "        self.classifier.add_module('lin2', nn.Linear(500, 300))\n",
    "        self.classifier.add_module('sig2', torch.nn.Sigmoid())\n",
    "        self.classifier.add_module('lin3', nn.Linear(300, 100))\n",
    "        self.classifier.add_module('sig3', torch.nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view((x.size()[0], -1))\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        ### Другой способ задания сети - это описать слои и в forward их применять явно\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        #Увеличиваем кол-во выходных слоев с 84 - до 84*2 - потому что классов 100\n",
    "        self.fc2 = nn.Linear(120, 84*2)\n",
    "        self.fc3 = nn.Linear(84*2, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(a_in_planes, a_out_planes, a_stride=1):\n",
    "    return nn.Conv2d(a_in_planes, a_out_planes,  stride=a_stride,\n",
    "                     kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "def conv1x1(a_in_planes, a_out_planes, a_stride=1):\n",
    "    return nn.Conv2d(a_in_planes, a_out_planes,  stride=a_stride,\n",
    "                     kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "def x_downsample(a_in_channels):\n",
    "     return nn.Conv2d(a_in_channels, \n",
    "               a_in_channels*2,\n",
    "               kernel_size=1,\n",
    "               stride=2,\n",
    "               bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CifarResidualBlock(nn.Module):\n",
    "    def __init__(self, a_in_channels, make_downsample=True, use_skip_connection=True):\n",
    "        super(CifarResidualBlock, self).__init__()\n",
    "        self.use_skip_connection = use_skip_connection\n",
    "        \n",
    "        self.make_downsample = make_downsample\n",
    "        \n",
    "        if make_downsample: \n",
    "            coef = 2\n",
    "        else: \n",
    "            coef = 1  \n",
    "        if make_downsample:\n",
    "            self.conv3 = conv3x3(a_in_channels, a_in_channels*2, 2)\n",
    "            self.conv1 = conv3x3(a_in_channels*2, a_in_channels*2, 1)\n",
    "            self.conv2 = x_downsample(a_in_channels)\n",
    "            \n",
    "            self.bn1 = nn.BatchNorm2d(a_in_channels*coef)\n",
    "            self.bn2 = nn.BatchNorm2d(a_in_channels*coef)\n",
    "            \n",
    "        else:\n",
    "            self.conv3 = conv3x3(a_in_channels,a_in_channels)\n",
    "            self.conv2 = conv3x3(a_in_channels,a_in_channels)\n",
    "            self.bn1 = nn.BatchNorm2d(a_in_channels)\n",
    "            self.bn2 = nn.BatchNorm2d(a_in_channels)\n",
    "        \n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if (self.make_downsample):\n",
    "            if (self.use_skip_connection):\n",
    "                copy_x = x\n",
    "            x = self.conv3(x)\n",
    "            \n",
    "            x = self.bn1(x)\n",
    "            x = self.relu1(x)\n",
    "            \n",
    "            x = self.conv1(x)\n",
    "            x = self.bn2(x)\n",
    "            x = self.relu1(x)\n",
    "            \n",
    "            if (self.use_skip_connection):\n",
    "                copy_x = self.conv2(copy_x)\n",
    "                x = x + copy_x\n",
    "                x = self.relu1(x)\n",
    "                \n",
    "        else:\n",
    "            if (self.use_skip_connection):\n",
    "                copy_x = x\n",
    "            x = self.conv2(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu1(x)\n",
    "        \n",
    "            x = self.conv3(x)\n",
    "            x = self.bn2(x)\n",
    "            x = self.relu1(x)\n",
    "        \n",
    "            if (self.use_skip_connection):\n",
    "                x = x + copy_x\n",
    "                x = self.relu1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarResidualBottleneckBlock(nn.Module):\n",
    "    \n",
    "    BOTTLENECK_COEF = 4\n",
    "    \n",
    "    def __init__(self, a_in_channels, make_downsample=True, use_skip_connection=True):\n",
    "        super(CifarResidualBottleneckBlock, self).__init__()\n",
    "        self.use_skip_connection = use_skip_connection\n",
    "        self.make_downsample = make_downsample\n",
    "        if make_downsample: \n",
    "            coef = 2\n",
    "        else: \n",
    "            coef = 1  \n",
    "                   \n",
    "        if make_downsample:\n",
    "            self.conv1 = conv1x1(a_in_channels, int(a_in_channels/2), 1)\n",
    "            self.conv2 = conv3x3(int(a_in_channels/2), int(a_in_channels/2), 2)\n",
    "            self.conv3 = conv1x1(int(a_in_channels/2), a_in_channels*2, 1)\n",
    "            self.conv4 = x_downsample(a_in_channels)\n",
    "            \n",
    "            self.bn1 = nn.BatchNorm2d(int(a_in_channels/2))\n",
    "            self.bn2 = nn.BatchNorm2d(int(a_in_channels/2))\n",
    "            self.bn3 = nn.BatchNorm2d(a_in_channels*2)\n",
    "            \n",
    "        else:\n",
    "            self.conv1 = conv1x1(a_in_channels, int(a_in_channels/4), 1)\n",
    "            self.conv2 = conv3x3(int(a_in_channels/4), int(a_in_channels/4), 1)\n",
    "            self.conv3 = conv1x1(int(a_in_channels/4), a_in_channels, 1)\n",
    "            self.bn1 = nn.BatchNorm2d(int(a_in_channels/4))\n",
    "            self.bn2 = nn.BatchNorm2d(int(a_in_channels/4))\n",
    "            self.bn3 = nn.BatchNorm2d(a_in_channels)\n",
    "        \n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "    \n",
    "            \n",
    "    def forward(self, x):\n",
    "        if (self.make_downsample):\n",
    "            if (self.use_skip_connection):\n",
    "                copy_x = x\n",
    "            x = self.conv1(x)\n",
    "            \n",
    "            x = self.bn1(x)\n",
    "            x = self.relu1(x)\n",
    "            \n",
    "            x = self.conv2(x)\n",
    "            x = self.bn2(x)\n",
    "            x = self.relu1(x)\n",
    "            \n",
    "            x = self.conv3(x)\n",
    "            x = self.bn3(x)\n",
    "            x = self.relu1(x)\n",
    "            \n",
    "            if (self.use_skip_connection):\n",
    "                copy_x = self.conv4(copy_x)\n",
    "                x = x + copy_x\n",
    "                x = self.relu1(x)\n",
    "                \n",
    "        else:\n",
    "            if (self.use_skip_connection):\n",
    "                copy_x = x\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.relu1(x)\n",
    "        \n",
    "            x = self.conv2(x)\n",
    "            x = self.bn2(x)\n",
    "            x = self.relu1(x)\n",
    "            \n",
    "            x = self.conv3(x)\n",
    "            x = self.bn3(x)\n",
    "            x = self.relu1(x)\n",
    "        \n",
    "            if (self.use_skip_connection):\n",
    "                x = x + copy_x\n",
    "                x = self.relu1(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CifarResNet, self).__init__()\n",
    "        \n",
    "        #TODO нужно добавить блоков resnet и других слоев при необходимости\n",
    "        \n",
    "        self.features = nn.Sequential()\n",
    "        \n",
    "        self.features.add_module('conv3x3', conv3x3(3,32))\n",
    "        self.features.add_module('bn', nn.BatchNorm2d(32))\n",
    "        self.features.add_module('relu', nn.LeakyReLU())\n",
    "        \n",
    "        self.features.add_module('res_block1', CifarResidualBlock(32))\n",
    "        self.features.add_module('res_block_1', CifarResidualBlock(64, make_downsample=False))\n",
    "        self.features.add_module('res_block2', CifarResidualBlock(64))\n",
    "        self.features.add_module('res_block_2', CifarResidualBlock(128, make_downsample=False))\n",
    "        self.features.add_module('res_block3', CifarResidualBlock(128))\n",
    "        self.features.add_module('res_block_3', CifarResidualBlock(256, make_downsample=False))\n",
    "        self.features.add_module('res_block4', CifarResidualBlock(256))\n",
    "        \n",
    "        self.global_avg_pooling = nn.AvgPool2d(kernel_size=2)\n",
    "        self.fc_classifier = nn.Linear(512, 100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.global_avg_pooling(x)        \n",
    "        x = x.view((x.size()[0], -1))        \n",
    "        x = self.fc_classifier(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 0.0949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/nmnt/media/home/farshov/anaconda3/lib/python3.7/site-packages/IPython/core/magics/execution.py\", line 1284, in time\n",
      "    out = eval(code, glob, local_ns)\n",
      "  File \"<timed eval>\", line 1, in <module>\n",
      "  File \"<ipython-input-22-55067c99b50f>\", line 52, in train_network\n",
      "    new_labels = labels.to('cpu')\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/nmnt/media/home/farshov/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/nmnt/media/home/farshov/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/nmnt/media/home/farshov/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/nmnt/media/home/farshov/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/nmnt/media/home/farshov/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/nmnt/media/home/farshov/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/nmnt/media/home/farshov/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/nmnt/media/home/farshov/anaconda3/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/nmnt/media/home/farshov/anaconda3/lib/python3.7/inspect.py\", line 70, in ismodule\n",
      "    return isinstance(object, types.ModuleType)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "resnet = CifarResNet()\n",
    "%time train_network(resnet, torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1549630534704/work/aten/src/THNN/generic/ClassNLLCriterion.c:93",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-626beb6050ad>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(a_net, a_device, dataloader_train_norm, a_epochs, a_batch_size, a_lr)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1788\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1549630534704/work/aten/src/THNN/generic/ClassNLLCriterion.c:93"
     ]
    }
   ],
   "source": [
    "dense_net = StupidDenseNet()\n",
    "%time train_network(dense_net, torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1549630534704/work/aten/src/THNN/generic/ClassNLLCriterion.c:93",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-626beb6050ad>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(a_net, a_device, dataloader_train_norm, a_epochs, a_batch_size, a_lr)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1788\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1549630534704/work/aten/src/THNN/generic/ClassNLLCriterion.c:93"
     ]
    }
   ],
   "source": [
    "lenet = LeNet()\n",
    "%time train_network(lenet, torch.device('cpu'), a_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1549630534704/work/aten/src/THNN/generic/ClassNLLCriterion.c:93",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-626beb6050ad>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(a_net, a_device, dataloader_train_norm, a_epochs, a_batch_size, a_lr)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1788\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `cur_target >= 0 && cur_target < n_classes' failed.  at /opt/conda/conda-bld/pytorch_1549630534704/work/aten/src/THNN/generic/ClassNLLCriterion.c:93"
     ]
    }
   ],
   "source": [
    "lenet = LeNet()\n",
    "%time train_network(lenet, torch.device(DEVICE), a_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 0.0533\n",
      "Epoch  1 0.0795\n",
      "Epoch  2 0.095\n",
      "Epoch  3 0.099\n",
      "Epoch  4 0.1006\n",
      "Epoch  5 0.1037\n",
      "Epoch  6 0.1041\n",
      "Epoch  7 0.104\n",
      "Epoch  8 0.1057\n",
      "Epoch  9 0.112\n",
      "Epoch  10 0.1103\n",
      "Epoch  11 0.1133\n",
      "Epoch  12 0.1128\n",
      "Epoch  13 0.1133\n",
      "Epoch  14 0.1163\n",
      "Epoch  15 0.1183\n",
      "Epoch  16 0.1136\n",
      "Epoch  17 0.1135\n",
      "Epoch  18 0.1119\n",
      "Epoch  19 0.1147\n",
      "Epoch  20 0.1182\n",
      "Epoch  21 0.1171\n",
      "Epoch  22 0.1155\n",
      "Epoch  23 0.1178\n",
      "Epoch  24 0.1167\n",
      "Epoch  25 0.1191\n",
      "Epoch  26 0.1227\n",
      "Epoch  27 0.1188\n",
      "Epoch  28 0.12\n",
      "Epoch  29 0.1248\n",
      "Epoch  30 0.1236\n",
      "Epoch  31 0.1197\n",
      "Epoch  32 0.1225\n",
      "Epoch  33 0.1213\n",
      "Epoch  34 0.121\n",
      "Epoch  35 0.1208\n",
      "Epoch  36 0.1169\n",
      "Epoch  37 0.1221\n",
      "Epoch  38 0.1196\n",
      "Epoch  39 0.1267\n",
      "Epoch  40 0.1246\n",
      "Epoch  41 0.1199\n",
      "Epoch  42 0.1199\n",
      "Epoch  43 0.1251\n",
      "Epoch  44 0.1237\n",
      "Epoch  45 0.1254\n",
      "Epoch  46 0.1237\n",
      "Epoch  47 0.1274\n",
      "Epoch  48 0.1263\n",
      "Epoch  49 0.1244\n",
      "Epoch  50 0.1241\n",
      "Epoch  51 0.1264\n",
      "Epoch  52 0.1277\n",
      "Epoch  53 0.1269\n",
      "Epoch  54 0.1231\n",
      "Epoch  55 0.1254\n",
      "Epoch  56 0.1277\n",
      "Epoch  57 0.1242\n",
      "Epoch  58 0.1283\n",
      "Epoch  59 0.1258\n",
      "Epoch  60 0.1296\n",
      "Epoch  61 0.1304\n",
      "Epoch  62 0.1253\n",
      "Epoch  63 0.1322\n",
      "Epoch  64 0.1288\n",
      "Epoch  65 0.1279\n",
      "Epoch  66 0.1288\n",
      "Epoch  67 0.1281\n",
      "Epoch  68 0.1292\n",
      "Epoch  69 0.1291\n",
      "Epoch  70 0.1258\n",
      "Epoch  71 0.1313\n",
      "Epoch  72 0.1292\n",
      "Epoch  73 0.1276\n",
      "Epoch  74 0.1273\n",
      "Epoch  75 0.1326\n",
      "Epoch  76 0.1258\n",
      "Epoch  77 0.1279\n",
      "Epoch  78 0.1279\n",
      "Epoch  79 0.1308\n",
      "Epoch  80 0.1322\n",
      "Epoch  81 0.1323\n",
      "Epoch  82 0.1764\n",
      "Epoch  83 0.195\n",
      "Epoch  84 0.2051\n",
      "Epoch  85 0.2119\n",
      "Epoch  86 0.2145\n",
      "Epoch  87 0.2242\n",
      "Epoch  88 0.2262\n",
      "Epoch  89 0.233\n",
      "Epoch  90 0.233\n",
      "Epoch  91 0.2361\n",
      "Epoch  92 0.2402\n",
      "Epoch  93 0.2425\n",
      "Epoch  94 0.2457\n",
      "Epoch  95 0.2471\n",
      "Epoch  96 0.2468\n",
      "Epoch  97 0.2529\n",
      "Epoch  98 0.2538\n",
      "Epoch  99 0.2579\n",
      "Epoch  100 0.2599\n",
      "Epoch  101 0.261\n",
      "Epoch  102 0.2626\n",
      "Epoch  103 0.2687\n",
      "Epoch  104 0.2693\n",
      "Epoch  105 0.2735\n",
      "Epoch  106 0.2725\n",
      "Epoch  107 0.2715\n",
      "Epoch  108 0.2741\n",
      "Epoch  109 0.2763\n",
      "Epoch  110 0.2801\n",
      "Epoch  111 0.2814\n",
      "Epoch  112 0.2831\n",
      "Epoch  113 0.2827\n",
      "Epoch  114 0.2862\n",
      "Epoch  115 0.2864\n",
      "Epoch  116 0.2867\n",
      "Epoch  117 0.2857\n",
      "Epoch  118 0.2931\n",
      "Epoch  119 0.2902\n",
      "Epoch  120 0.2955\n",
      "Epoch  121 0.2938\n",
      "Epoch  122 0.2965\n",
      "Epoch  123 0.3186\n",
      "Epoch  124 0.325\n",
      "Epoch  125 0.3244\n",
      "Epoch  126 0.3245\n",
      "Epoch  127 0.3278\n",
      "Epoch  128 0.3293\n",
      "Epoch  129 0.3287\n",
      "Epoch  130 0.3288\n",
      "Epoch  131 0.3301\n",
      "Epoch  132 0.33\n",
      "Epoch  133 0.3322\n",
      "Epoch  134 0.3311\n",
      "Epoch  135 0.3324\n",
      "Epoch  136 0.3337\n",
      "Epoch  137 0.3304\n",
      "Epoch  138 0.3323\n",
      "Epoch  139 0.3328\n",
      "Epoch  140 0.3368\n",
      "Epoch  141 0.3333\n",
      "Epoch  142 0.3368\n",
      "Epoch  143 0.3354\n",
      "Epoch  144 0.339\n",
      "Epoch  145 0.3363\n",
      "Epoch  146 0.3357\n",
      "Epoch  147 0.3346\n",
      "Epoch  148 0.3336\n",
      "Epoch  149 0.337\n",
      "Epoch  150 0.3377\n",
      "Epoch  151 0.3379\n",
      "Epoch  152 0.334\n",
      "Epoch  153 0.3396\n",
      "Epoch  154 0.3356\n",
      "Epoch  155 0.3376\n",
      "Epoch  156 0.3382\n",
      "Epoch  157 0.3421\n",
      "Epoch  158 0.3389\n",
      "Epoch  159 0.339\n",
      "Epoch  160 0.3406\n",
      "Epoch  161 0.3408\n",
      "Epoch  162 0.3394\n",
      "Epoch  163 0.3405\n",
      "Finished Training\n",
      "CPU times: user 3h 22min 54s, sys: 10min 21s, total: 3h 33min 15s\n",
      "Wall time: 1h 17min 38s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenet = LeNet()\n",
    "%time train_network(lenet, torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Важно переключить сеть в режим eval - иначе dropout будет работать некорректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_solution(a_net, a_device):\n",
    "    res = []\n",
    "    net = a_net.eval()\n",
    "    for item in dataloader_test_norm:\n",
    "        inputs = item.to(a_device)\n",
    "        outputs = net(inputs) \n",
    "\n",
    "        res += prediction2classes(outputs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# my_solution = make_solution(dense_net, DEVICE)\n",
    "my_solution = make_solution(resnet, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('my_solution.csv', 'w') as fout:\n",
    "    print('Id', 'Prediction', sep=',', file=fout)\n",
    "    for i, prediction in enumerate(my_solution):\n",
    "        print(i, prediction, sep=',', file=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
