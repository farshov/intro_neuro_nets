{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ №5 Сегментация\n",
    "Реализация сети для сегметации объектов.\n",
    "\n",
    "__Задача__ сделать работоспособную сеть для сегментирования изображений авто на основе предложенного шаблона\n",
    "\n",
    "\n",
    "![Segmentation](../img/Segment04.png)\n",
    "\n",
    "### Что делаем\n",
    "Реализуем сверточную сеть для семантической сегментации, downsample->upsample -> Классификация каждого пикселя выходного изображения: 0 - не авто, 1 - авто. Выход картинка с x каналами, для классификации.\n",
    "1. В файле model.py   - имплементировать модель вместо заглушки\n",
    "2. В файле train.py - поставить правильный loss\n",
    "\n",
    "### Данные\n",
    "[Carvana](https://cloud.mail.ru/public/3tdq/AvtaHkDAb)\n",
    "\n",
    "### Зависимости\n",
    " - tensorflow  - поддержка tensorboard\n",
    " - tensorboardx - тензор боард для pytorch\n",
    " - tqdm         - пакет для отрисовки прогресс баров\n",
    "\n",
    "### Запуск пакета\n",
    "_ По умолчанию все данные лежат в папке ./data/. Если вы положили их в другую папку, то поправте в скрипте train.py пути _\n",
    "<br/>\n",
    "Запускаем обучение сети\n",
    "python train.py\n",
    "\n",
    "Результаты обучение можно наблюдать в tensorboard\n",
    "\n",
    "Запуск tensorboard --log ./od_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты\n",
    "1. Код model.py, train.py\n",
    "2. Модель state_dicts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тут нужно сделать загрузку состояния вашей модели, код модели в ноутбук тащить не нужно, достаточно сделать import model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as dt\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "to_img = ToPILImage()\n",
    "\n",
    "\n",
    "class CarvanaDataset(dt.Dataset):\n",
    "    \"\"\" \n",
    "        Carvana features dataset.  Override torch Dataset class to implements reading from h5 files\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path, mask_path, input_size=224):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path (string): Path to the images data files.\n",
    "            mask_path (string): Path were images masks are placed\n",
    "        \"\"\"\n",
    "        self.files = os.listdir(data_path)\n",
    "        self.files.sort()\n",
    "        self.mask_files = os.listdir(mask_path)\n",
    "        self.mask_files.sort()\n",
    "        self.data_path = data_path\n",
    "        self.mask_path = mask_path\n",
    "        assert (len(self.files) == len(self.mask_files))\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.preprocess = transforms.Compose([\n",
    "            transforms.Scale((input_size, input_size)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def pil_load(self, path, is_input=True):\n",
    "        # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "        with open(path, 'rb') as f:\n",
    "            with Image.open(f) as img:\n",
    "                return img.convert('RGB')\n",
    "\n",
    "    def pil_save(self, t, img_path):\n",
    "        a = to_img(t)\n",
    "        a.save(img_path, 'PNG')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f_name = os.path.join(self.data_path, self.files[idx])\n",
    "        m_name = os.path.join(self.mask_path, self.mask_files[idx])\n",
    "\n",
    "        if os.path.exists(f_name) == False:\n",
    "            raise Exception('Missing file with name ' + f_name + ' in dataset')\n",
    "\n",
    "        input = self.pil_load(f_name)\n",
    "        target = self.pil_load(m_name, False)\n",
    "\n",
    "        input = self.preprocess(input)\n",
    "        target = self.preprocess(target)\n",
    "        target = torch.sum(target, dim=0).unsqueeze(0)\n",
    "        target[ torch.gt(target, 0) ] = 1\n",
    "\n",
    "        return input, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def conv_bn_relu(in_planes, out_planes, kernel=3, stride=1):\n",
    "    net = nn.Sequential(nn.Conv2d(in_planes, out_planes, kernel_size=kernel, stride=stride, padding=1),\n",
    "                        nn.BatchNorm2d(num_features=out_planes),\n",
    "                        nn.ReLU(True))\n",
    "    return net;\n",
    "\n",
    "def transpose_conv_bn_relu(in_planes, out_planes, kernel=3, stride=1):\n",
    "    net = nn.Sequential(nn.ConvTranspose2d(in_planes, out_planes, kernel_size=kernel, stride=stride, padding=1),\n",
    "                        nn.BatchNorm2d(num_features=out_planes),\n",
    "                        nn.ReLU(True))\n",
    "    return net;\n",
    "\n",
    "# input size Bx3x224x224\n",
    "class SegmenterModel(nn.Module):\n",
    "    def __init__(self, in_size=3):\n",
    "        super(SegmenterModel, self).__init__()\n",
    "        \n",
    "        # implement your model here\n",
    "        D1 = 128\n",
    "        D2 = 256\n",
    "        D3 = 512\n",
    "        x = 2\n",
    "        \n",
    "        # in_size*224*224\n",
    "        \n",
    "        self.conv_bn_relu1 = nn.Sequential()                    \n",
    "        self.conv_bn_relu1.add_module('conv_bn_relu1_1', conv_bn_relu(in_size, D1))\n",
    "        self.conv_bn_relu1.add_module('conv_bn_relu1_2', conv_bn_relu(D1, D1))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "\n",
    "        # D1*112*112\n",
    "        \n",
    "        self.conv_bn_relu2 = nn.Sequential()\n",
    "        self.conv_bn_relu2.add_module('conv_bn_relu2_1', conv_bn_relu(D1, D2))\n",
    "        self.conv_bn_relu2.add_module('conv_bn_relu2_2', conv_bn_relu(D2, D2))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        \n",
    "        # D2*56*56\n",
    "        \n",
    "        self.conv_bn_relu3 = nn.Sequential()\n",
    "        self.conv_bn_relu3.add_module('conv_bn_relu3_1', conv_bn_relu(D2, D3))\n",
    "        self.conv_bn_relu3.add_module('conv_bn_relu3_2', conv_bn_relu(D3, D3))\n",
    "        \n",
    "        # D3*56*56\n",
    "        \n",
    "        self.transpose_conv_bn_relu3 = nn.Sequential()\n",
    "        self.transpose_conv_bn_relu3.add_module('transpose_conv_bn_relu3_1', transpose_conv_bn_relu(D3, D3))\n",
    "        self.transpose_conv_bn_relu3.add_module('transpose_conv_bn_relu3_2', transpose_conv_bn_relu(D3, D2))\n",
    "        \n",
    "        # D2*56*56\n",
    "        \n",
    "        self.unpool2 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.transpose_conv_bn_relu2 = nn.Sequential()\n",
    "        self.transpose_conv_bn_relu2.add_module('transpose_conv_bn_relu2_1', transpose_conv_bn_relu(D2, D2))\n",
    "        self.transpose_conv_bn_relu2.add_module('transpose_conv_bn_relu2_2', transpose_conv_bn_relu(D2, D1))\n",
    "        \n",
    "        # D2*112*112\n",
    "        \n",
    "        self.unpool1 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.transpose_conv_bn_relu1 = nn.Sequential()\n",
    "        self.transpose_conv_bn_relu1.add_module('transpose_conv_bn_relu1_1', transpose_conv_bn_relu(D1, D1)) \n",
    "        self.transpose_conv_bn_relu1.add_module('transpose_conv_bn_relu1_2', transpose_conv_bn_relu(D1, D1))\n",
    "        \n",
    "        self.out = nn.Conv2d(D1, 2, kernel_size=3, padding=1, stride=1)\n",
    "        # x*224*224\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        output = self.conv_bn_relu1(x)\n",
    "        output, indices1 = self.pool1(output)\n",
    "        \n",
    "        output = self.conv_bn_relu2(output)\n",
    "        output, indices2 = self.pool2(output)\n",
    "        \n",
    "        output = self.conv_bn_relu3(output)\n",
    "        output = self.transpose_conv_bn_relu3(output)\n",
    "        \n",
    "        output = self.unpool2(output, indices2)\n",
    "        output = self.transpose_conv_bn_relu2(output)\n",
    "        \n",
    "        output = self.unpool1(output, indices1)\n",
    "        output = self.transpose_conv_bn_relu1(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/916 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 113/916 [00:42<05:02,  2.65it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as dt\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "import os\n",
    "from tqdm import *\n",
    "import numpy as np\n",
    "\n",
    "useCuda =True\n",
    "n_epoch = 50\n",
    "log = './log_1/'\n",
    "train = './data/train/'\n",
    "train_masks = './data/train_masks/'\n",
    "test = './data/test/'\n",
    "test_masks = './data/test_masks'\n",
    "\n",
    "if os.path.exists(log) == False:\n",
    "    os.mkdir(log)\n",
    "tb_writer = SummaryWriter(log_dir='log_1')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "     Тут модель, которую мы реализовали в файле model.py\n",
    "    \"\"\"\n",
    "    m = SegmenterModel()\n",
    "    \"\"\"\n",
    "    Делаем критерий, который будем оптимайзить\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(m.parameters(), lr=0.001)\n",
    "\n",
    "    if useCuda == True:\n",
    "        m = m.cuda()\n",
    "        criterion= criterion.cuda()\n",
    "\n",
    "    ds = CarvanaDataset(train, train_masks)\n",
    "    ds_test = CarvanaDataset(test, test_masks)\n",
    "\n",
    "    dl      = dt.DataLoader(ds, shuffle=True, num_workers=4, batch_size=5)\n",
    "    dl_test = dt.DataLoader(ds_test, shuffle=False, num_workers=4, batch_size=5)\n",
    "\n",
    "    global_iter = 0\n",
    "    for epoch in range(0, n_epoch):\n",
    "        print (\"Current epoch: \", epoch)\n",
    "        epoch_loss = 0\n",
    "        m.train(True)\n",
    "        for iter, (i, t) in enumerate(tqdm( dl) ):\n",
    "            i = Variable(i)\n",
    "            t = Variable(t).long()\n",
    "            if useCuda :\n",
    "                i = i.cuda()\n",
    "                t = t.cuda()\n",
    "            o = m(i)\n",
    "            t = t.view((t.shape[0], t.shape[2], t.shape[3]))\n",
    "            loss = criterion(o, t)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            global_iter += 1\n",
    "            epoch_loss += loss.data\n",
    "\n",
    "        epoch_loss = epoch_loss / float(len(ds))\n",
    "        print (\"Epoch loss\", epoch_loss)\n",
    "        tb_writer.add_scalar('Loss/Train', epoch_loss, epoch)\n",
    "\n",
    "        print (\"Make test\")\n",
    "        test_loss = 0\n",
    "        m.train(False)\n",
    "\n",
    "        tb_out = np.random.choice(range(0, len(dl_test)), 3 )\n",
    "        for iter, (i, t) in enumerate(tqdm(dl_test)):\n",
    "            i = Variable(i, volatile = True)\n",
    "            t = Variable(t, volatile = True).long()\n",
    "            if useCuda :\n",
    "                i = i.cuda()\n",
    "                t = t.cuda()\n",
    "            o = m(i)\n",
    "            t = t.view((t.shape[0], t.shape[2], t.shape[3]))\n",
    "            loss = criterion(o, t)\n",
    "            o = torch.argmax(o, dim=1)\n",
    "            test_loss += loss.data\n",
    "\n",
    "            for k, c in enumerate(tb_out):\n",
    "                if c == iter:\n",
    "                    tb_writer.add_image('Image/Test_input_%d'%k,  i[0].cpu(), epoch)  # Tensor\n",
    "                    tb_writer.add_image('Image/Test_target_%d'%k, t[0].cpu(), epoch)  # Tensor\n",
    "                    tb_writer.add_image('Image/Test_output_%d'%k, o[0].cpu(), epoch)  # Tensor\n",
    "\n",
    "        test_loss = test_loss / float(len(ds_test))\n",
    "        print (\"Test loss\", test_loss)\n",
    "        tb_writer.add_scalar('Loss/Test', test_loss, epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тут нужно нарисовать картинки, с результатими сегментации из тестового сета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Для рандомного изображения рисуем его маску сгенерированную сеткой, само изображение и результат сегментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
